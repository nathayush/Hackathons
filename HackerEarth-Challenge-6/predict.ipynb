{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# from matplotlib import style\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all data and merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'train.csv')\n",
    "df_test = pd.read_csv(r'test.csv')\n",
    "# df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_structure = pd.read_csv(r'Building_Structure.csv')\n",
    "df_ownership = pd.read_csv(r'Building_Ownership_Use.csv')\n",
    "\n",
    "df_train = pd.merge(df_train, df_structure, how='left', left_on='building_id', right_on='building_id')\n",
    "df_test = pd.merge(df_test, df_structure, how='left', left_on='building_id', right_on='building_id')\n",
    "\n",
    "df_train = pd.merge(df_train, df_ownership, how='left', left_on='building_id', right_on='building_id')\n",
    "df_test = pd.merge(df_test, df_ownership, how='left', left_on='building_id', right_on='building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode all values to int so that the model can read them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [df_train, df_test]\n",
    "\n",
    "# LE_condition_post_eq = LE_legal_ownership_status = LE_plan_configuration = LE_position = LE_other_floor_type = LE_ground_floor_type = LE_roof_type = LE_foundation_type = LE_land_surface_condition = LE_area_assesed = LE_damage_grade = preprocessing.LabelEncoder()\n",
    "LE_condition_post_eq = preprocessing.LabelEncoder()\n",
    "LE_condition_post_eq.fit(df_train['condition_post_eq'])\n",
    "LE_legal_ownership_status = preprocessing.LabelEncoder()\n",
    "LE_legal_ownership_status.fit(df_train['legal_ownership_status'])\n",
    "LE_plan_configuration = preprocessing.LabelEncoder()\n",
    "LE_plan_configuration.fit(df_train['plan_configuration'])\n",
    "LE_position = preprocessing.LabelEncoder()\n",
    "LE_position.fit(df_train['position'])\n",
    "LE_other_floor_type = preprocessing.LabelEncoder()\n",
    "LE_other_floor_type.fit(df_train['other_floor_type'])\n",
    "LE_ground_floor_type = preprocessing.LabelEncoder()\n",
    "LE_ground_floor_type.fit(df_train['ground_floor_type'])\n",
    "LE_roof_type = preprocessing.LabelEncoder()\n",
    "LE_roof_type.fit(df_train['roof_type'])\n",
    "LE_foundation_type = preprocessing.LabelEncoder()\n",
    "LE_foundation_type.fit(df_train['foundation_type'])\n",
    "LE_land_surface_condition = preprocessing.LabelEncoder()\n",
    "LE_land_surface_condition.fit(df_train['land_surface_condition'])\n",
    "LE_area_assesed = preprocessing.LabelEncoder()\n",
    "LE_area_assesed.fit(df_train['area_assesed'])\n",
    "LE_damage_grade = preprocessing.LabelEncoder()\n",
    "LE_damage_grade.fit(df_train['damage_grade'])\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['has_geotechnical_risk'] = dataset['has_geotechnical_risk'].astype('int64')\n",
    "    dataset['count_families'] = dataset['count_families'].fillna(0)\n",
    "    dataset['count_families'] = dataset['count_families'].astype('int64')\n",
    "    dataset['has_secondary_use'] = dataset['has_secondary_use'].astype('int64')\n",
    "    dataset['has_repair_started'] = dataset['has_repair_started'].fillna(0)\n",
    "    dataset['has_repair_started'] = dataset['has_repair_started'].astype('int64')\n",
    "    \n",
    "    dataset['floor_diff'] = dataset['count_floors_pre_eq']-dataset['count_floors_post_eq']\n",
    "    dataset['height_diff'] = dataset['height_ft_pre_eq']-dataset['height_ft_post_eq']\n",
    "    \n",
    "    dataset['condition_post_eq'] = LE_condition_post_eq.transform(dataset['condition_post_eq'])\n",
    "    dataset['legal_ownership_status'] = LE_legal_ownership_status.transform(dataset['legal_ownership_status'])\n",
    "    dataset['plan_configuration'] = LE_plan_configuration.transform(dataset['plan_configuration'])\n",
    "    dataset['position'] = LE_position.transform(dataset['position'])\n",
    "    dataset['other_floor_type'] = LE_other_floor_type.transform(dataset['other_floor_type'])\n",
    "    dataset['ground_floor_type'] = LE_ground_floor_type.transform(dataset['ground_floor_type'])\n",
    "    dataset['roof_type'] = LE_roof_type.transform(dataset['roof_type'])\n",
    "    dataset['foundation_type'] = LE_foundation_type.transform(dataset['foundation_type'])\n",
    "    dataset['land_surface_condition'] = LE_land_surface_condition.transform(dataset['land_surface_condition'])\n",
    "    dataset['area_assesed'] = LE_area_assesed.transform(dataset['area_assesed'])\n",
    "for dataset in [df_train]:\n",
    "    dataset['damage_grade'] = LE_damage_grade.transform(dataset['damage_grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop a few features which have low importance for RandomForest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['height_ft_pre_eq', 'height_ft_post_eq', 'count_floors_pre_eq', 'count_floors_post_eq', 'has_secondary_use_use_police', 'has_secondary_use_gov_office', 'has_secondary_use_health_post', 'has_secondary_use_industry', 'has_secondary_use_school', 'has_secondary_use_institution', 'has_geotechnical_risk_liquefaction', 'has_geotechnical_risk_other', 'has_secondary_use_other', 'has_secondary_use_rental', 'has_geotechnical_risk_flood', 'has_superstructure_other'], axis=1)\n",
    "df_test = df_test.drop(['height_ft_pre_eq', 'height_ft_post_eq', 'count_floors_pre_eq', 'count_floors_post_eq', 'has_secondary_use_use_police', 'has_secondary_use_gov_office', 'has_secondary_use_health_post', 'has_secondary_use_industry', 'has_secondary_use_school', 'has_secondary_use_institution', 'has_geotechnical_risk_liquefaction', 'has_geotechnical_risk_other', 'has_secondary_use_other', 'has_secondary_use_rental', 'has_geotechnical_risk_flood', 'has_superstructure_other'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check feature correlations and remove highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "# df_train = df_train.drop(to_drop, axis=1)\n",
    "# df_test = df_test.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop([\"damage_grade\", \"building_id\"], axis=1).copy()\n",
    "Y_train = df_train[\"damage_grade\"]\n",
    "X_test  = df_test.drop(\"building_id\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and validation sets from all training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(X_train , Y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling the training set because of imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "# x_train_res, y_train_res = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random hyperparameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_random.fit(x_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=1000, max_features='sqrt')\n",
    "random_forest.fit(x_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"macro\"))\n",
    "'''0.7505923689189196 : 500'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check feature importance in the RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(random_forest.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.plot.bar(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict damage for test set and save into submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "df_test['damage_grade'] = LE_damage_grade.inverse_transform(Y_pred)\n",
    "df_test[['building_id' , 'damage_grade']].to_csv('submit_1.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
